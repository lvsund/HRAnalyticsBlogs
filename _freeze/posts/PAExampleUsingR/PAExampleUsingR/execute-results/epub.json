{
  "hash": "de2886c4efac42334ba084fc518d7e32",
  "result": {
    "markdown": "---\ntitle: \"People Analytics - An Example Using R\"\nauthor: \"Lyndon Sundmark, MBA\"\ndate: \"2016-02-28\"\ncategories: [HR Analytics]\n---\n\n\n\n\n\n# Introduction\n\nOver last 18 months or so I have been writing LinkedIn blog articles on analytics and their potential use for HR. Most of these articles have hinted that there are many obstacles to the application of analytics to HR.\n\nThese obstacles for widespread evidence and use are predominantly human not technical:\n\n-   **Data generation is not the problem.** HR data availability and accessability has never been greater to HR professionals.\n-   **Technology is not problem.** Data science, machine learning, and analytic tools are exploding on to the scene these days. Whether it is enhancements to the R statistical package, or other statistical packages, or developments in other tools like Microsoft Azure Machine Learning or RapidMiner as examples- there have never been more tools to be brought to bear on HR data.\n-   **Application of the tools on the data IS the problem.** (In this case lack thereof).\n\nThis lack of application can occur from:\n\n1.  **The HR profession not seeing that most of HR is highly technical.** In the past HR might have acknowleged the traditional areas such as salary and wage administration, or labor relations/collective bargaining costing was technical because it was seen as heavily dependent on calculation and data. But for most of the rest of the HR domain HR professionals think its non-technical- whether it be recruitment,training, Health and Safety, Benefits, engagement. To be sure, there are the 'human' sides of all areas of HR, but they are all 'as much technical as well. The technical has far too long being ignored by HR professionals.\n\n    Dr. John Sullivan, in the following article:\n\n    http://www.tlnt.com/2013/02/26/how-google-is-using-people-analytics-to-completely-reinvent-hr/\n\n    describes this as 'reliance on relationships'. 'Relationships are the antithesis of analytical decsions making.' .\n\n2.  **Not enough HR professionals seeking the informational and analytical side of the picture in their university/college HR studies** in preparation for the HR field, and not enough universities/colleges offering studies in People Analytics.\n\n3.  **People Analytics- where it exists- being defining too narrowly as just HR metrics or predictive analytic tools to the HR domain.** These are part of the picture-yes- but 'data driven' can include much more of the statistical methods than just predictive.\n\n4.  **Obstacles that organizations inadvertently put in the way** - the 'sacred' requirement to develop a business case to 'get' resources to do any of this- particularly when 'starting' can be relatively free to develop proof of concepts.\n\nI am a firm believer in 'skunkworks' projects-making do with, and showing what can be done with, what you already have or with what can be obtained free. **You will often need to show by simple example what can be done** to justify more elaborate formal initiatives later and request additional formal resources.\n\nIts in that spirit, I wanted to walk through an example of People Analytics, and using free tools. **This wont be a full fledged best practices or even a robust example.** Rather it is intended to be a simple example to illustrate the process and some of the tools. Best practices and robustness comes with learning, use, and mastery over a period of time. Most of us need to start 'simply' to start 'somewhere'.\n\nThis example will be on one particular HR metric- absenteeism. **The data will be contrived.** But it will illustrate very rudimentary People Analytics using the R statistical programming language.\n\nBut before we get into this though, we should cover some basic helpful definitions and frameworks. These will help show why we are doing what we are doing.\n\n#Terminology\n\n##People Analytics First of all, I do prefer the term 'People Analytics' as compared to some of the other terms used interchangeably. Per the title, I am going to use the term 'People Analytics' the way its implicitly defined in the previous article link provided\n\n**People analytics is a data-driven approach to managing people at work.**\n\n'Data-driven' is key. It dispels any notion that data and measurement are not part of managing people. (Sorry to those of you who felt managing people was restricted only to 'reliance on relationships')\n\n**People Analytics is what happens when you apply Data Science and its principles to the realm of People Management (HR).**\n\nIt means 'analysis of data' **then** 'action'. And it means analysis **and** action. You are managing people through being 'data driven' A lot of organizations who try to get people analytics started, get stuck at creation of HR metrics and the use of Business Intelligence tools. These can be and are part of the people analytics picture, to be sure. But slicing and dicing , graphics and visualizations by themselves only take you so far. The addition of statistical analyses and taking informed action on your data are what will propel you forward.\n\nAnother reason why I like this definition is that 'data-driven' doesn't unintentionally restrict the type of analyses we do to be data driven. This can include exploratory analysis, predictive analysis, and experimental design. (Often people think only 'predictive' in the context of 'data driven'.)\n\nBecause we mention 'Data Science' in the context of People Analytics, it is important to define it next to understand why it is so tied to People Analytics.\n\n##Data Science I will share a few definitions.\n\n-   In their book Practical Data Science With R by Nina Zumel and John Mount https://www.manning.com/books/practical-data-science-with-r on page xix, they define data science as : '. managing the process that can transform hypotheses and data into actionable predictions.'\n\n-   Another definition is from the 'Field Guide to Data Science' by Booz, Allen , Hamilton- page 21: http://www.boozallen.com/insights/2015/12/data-science-field-guide-second-edition They define data science as : 'the art of turning data in actions'\n\n-   And still another definition from 'Data Science For Business' by Foster Provost And Tom Fawcett: http://shop.oreilly.com/product/0636920028918.do Data Science is a set of fundamental principles that guide the extraction of knowledge from data (page 2) . The ultimate goal of data science .improving decision making. (page 5)\n\nAll of these definitions clearly line up as being totally consistent with the above definition provided for People Analytics. It means transforming HR hunches, guesses (or really hypotheses) into information/data , analyses, and management actions- actions supported by the data.\n\n#A Framework\n\nZumel/Mount 's definition mentions 'process'. Processes are always require to 'transform' something from 'what it is' to 'what it is to become' - 'data' into 'actions'. This becomes a framework that can guide our efforts and understanding. In their book 'Practical Data Science With R' they define the following process for data science on page 6:\n\nData Science\n\n-   **Define a goal**\n-   **Collect and Manage Data**\n-   **Build The Model**\n-   **Evaluate and Critique Model**\n-   **Present Results and Document**\n-   **Deploy Model**\n\nI don't want to belabor the above process significantly in this blog article, because entire books have and are being written on the subjects of data science, predictive analytics, data mining etc. But I will make some general comments about the above steps to set the stage for the illustrative, simple ,rudimentary R example to follow.\n\n1.  **Define a goal** ,as mentioned above, means identifying first what HR management business problem you are trying to solve. Without a problem/issue we don't have a goal.\n2.  **Collect and Manage data.** At its simplest, you want a 'dataset' of information perceived to be relevant to the problem. The collection and management of data could be a simple extract from the corporate Human Resource Information System, or an output from an elaborate Data Warehousing/Business Intelligence tool used on HR information. For purpose of this blog article illustration we will use a simple CSV file. It also involves exploring the data both for data quality issues, and for an initial look at what the data may be telling you\n3.  **Build The Model.** This step really means, after you have defined the HR business problem or goal you are trying to achieve, you pick a data mining approach/tool that is designed to address that type of problem. With absenteeism as an HR issue, are you trying to predict employee with propensity to high absenteeism from those who aren't? Are you trying to predict future absenteeism rates? Are you trying to define what is normal absenteeism from that which is atypical or and anomaly? The business problem/goal determine the appropriate data mining tools to consider. Not exhaustive as a list, but common data mining approaches used in modelling are classification,regression, anomaly detection, time series, clustering, association analyses to name a few. These approaches take information/data as inputs , run them through statistical algorithms, and produce output.\n4.  **Evaluate and Critique Model.** Each data mining approach can have many different statistical algorithms to bring to bear on the data. The evaluation is both what algorithms provide the most consistent accurate predictions on new data, and do we have all the relevant data or do we need more types of data to increase predictive accuracy of model on new data. This can be necessarily repetitive and circular activity over time to improve the model\n5.  **Present Results And Document.** When we have gotten out model to an acceptable ,useful predictive level, we document our activity and present results. The definition of acceptable and useful is really relative to the organization, but in all cases would mean , results show improvement over what would have been otherwise. The principle behind data 'science' like any science, is that with the same data, people should be able to reproduce our findings/ results.\n6.  **Deploy Model.** The whole purpose of building the model ( which is on existing data) is to:\n\n-   use the model on future data when it becomes available, to predict or prevent something from happening before it occurs or\n-   to better understand our existing business problem to tailor more specific responses\n\nBoth R and other solutions allow you to save the model, so it can be used on other data. Lets now turn to a rudimentary People Analytics (Data driven People Management(HR) example in R.\n\n**This blog article is 'Part 1'.** The length of covering this in a single article would push the limits of comfortable reading length for a single article. So **part 1 will cover the first 2 steps** of the above process.\n\n#An R Example\n\n##1.Define the goal (or HR business problem/issue).\n\nA hypothetical company MFG has decided that it needs to at absenteeism. It wants answers to the following questions:\n\n-   **What is its rate of absenteeism?**\n-   **Does anyone have excessive absenteeism?**\n-   **Is is the same across the organization?**\n-   **Does it vary by gender?**\n-   **Does it vary by length of service or age?** Its guesses are that initially age and length of service may be related to absenteeism rates.\n-   **Can it predict next year's absenteeism?**\n-   **If so, how well can it predict?**\n-   **Can we reduce our absenteeism?**\n\nIf they can make future People Management decisions \"driven\" by what the data is telling them, then they will feel they have started the People Analytics journey.\n\n##2.Collect and Manage Data.\n\nLet us suppose this is a skunkworks project. Formal separate resources have not be identified for this initiative. Only an initial look at recent data is possible. The HRIS system is able to provide some rudimentary information covering absences only for 2015 It was able to generate the following information as a CSV file (comma separated values):\n\n-   EmployeeNumber\n-   Surname\n-   GivenName\n-   Gender\n-   City\n-   JobTitle\n-   DepartmentName\n-   StoreLocation\n-   Division\n-   Age\n-   LengthService\n-   AbsentHours\n-   BusinessUnit\n\n###Let's read in the data provided\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MFGEmployees <- read.csv(\"~/R Files/MFGEmployees4.csv\")\nMFGEmployees <- read.csv(\"MFGEmployees4.csv\")\nstr(MFGEmployees,width=80,strict.width =\"wrap\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t8336 obs. of  13 variables:\n$ EmployeeNumber: int 1 2 3 4 5 6 7 8 9 10 ...\n$ Surname : chr \"Gutierrez\" \"Hardwick\" \"Delgado\" \"Simon\" ...\n$ GivenName : chr \"Molly\" \"Stephen\" \"Chester\" \"Irene\" ...\n$ Gender : chr \"F\" \"M\" \"M\" \"F\" ...\n$ City : chr \"Burnaby\" \"Courtenay\" \"Richmond\" \"Victoria\" ...\n$ JobTitle : chr \"Baker\" \"Baker\" \"Baker\" \"Baker\" ...\n$ DepartmentName: chr \"Bakery\" \"Bakery\" \"Bakery\" \"Bakery\" ...\n$ StoreLocation : chr \"Burnaby\" \"Nanaimo\" \"Richmond\" \"Victoria\" ...\n$ Division : chr \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n$ Age : num 32 40.3 48.8 44.6 35.7 ...\n$ LengthService : num 6.02 5.53 4.39 3.08 3.62 ...\n$ AbsentHours : num 36.6 30.2 83.8 70 0 ...\n$ BusinessUnit : chr \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n```\n:::\n:::\n\n\n\n\n\nThe first thing we should do is check on quality of data. Data will rarely be clean or perfect when we receive it. Either questionnable data should be corrected(preferred) or deleted.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(MFGEmployees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n EmployeeNumber   Surname           GivenName            Gender         \n Min.   :   1   Length:8336        Length:8336        Length:8336       \n 1st Qu.:2085   Class :character   Class :character   Class :character  \n Median :4168   Mode  :character   Mode  :character   Mode  :character  \n Mean   :4168                                                           \n 3rd Qu.:6252                                                           \n Max.   :8336                                                           \n     City             JobTitle         DepartmentName     StoreLocation     \n Length:8336        Length:8336        Length:8336        Length:8336       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Division              Age         LengthService      AbsentHours    \n Length:8336        Min.   : 3.505   Min.   : 0.0121   Min.   :  0.00  \n Class :character   1st Qu.:35.299   1st Qu.: 3.5759   1st Qu.: 19.13  \n Mode  :character   Median :42.115   Median : 4.6002   Median : 56.01  \n                    Mean   :42.007   Mean   : 4.7829   Mean   : 61.28  \n                    3rd Qu.:48.667   3rd Qu.: 5.6239   3rd Qu.: 94.28  \n                    Max.   :77.938   Max.   :43.7352   Max.   :272.53  \n BusinessUnit      \n Length:8336       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n```\n:::\n:::\n\n\n\n\n\nThe only thing that stands out initially is that age has some questionable data- some one who is 3 and someone who is 77. The range for purposes of this example should be 18 to 65 .Normally you would want to clean the data by getting the correct information and then changing it. For expediency of the example we will delete the problem records\n\n###Clean the data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMFGEmployees<-subset(MFGEmployees,MFGEmployees$Age>=18)\nMFGEmployees<-subset(MFGEmployees,MFGEmployees$Age<=65)\n```\n:::\n\n\n\n\n\nNow lets summarize again with cleaned up data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(MFGEmployees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n EmployeeNumber   Surname           GivenName            Gender         \n Min.   :   1   Length:8165        Length:8165        Length:8165       \n 1st Qu.:2081   Class :character   Class :character   Class :character  \n Median :4166   Mode  :character   Mode  :character   Mode  :character  \n Mean   :4165                                                           \n 3rd Qu.:6245                                                           \n Max.   :8336                                                           \n     City             JobTitle         DepartmentName     StoreLocation     \n Length:8165        Length:8165        Length:8165        Length:8165       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Division              Age        LengthService       AbsentHours    \n Length:8165        Min.   :18.20   Min.   : 0.05328   Min.   :  0.00  \n Class :character   1st Qu.:35.46   1st Qu.: 3.58261   1st Qu.: 20.07  \n Mode  :character   Median :42.10   Median : 4.59800   Median : 55.86  \n                    Mean   :41.99   Mean   : 4.78887   Mean   : 60.47  \n                    3rd Qu.:48.51   3rd Qu.: 5.62358   3rd Qu.: 93.38  \n                    Max.   :65.00   Max.   :43.73524   Max.   :252.19  \n BusinessUnit      \n Length:8165       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n```\n:::\n:::\n\n\n\n\n\n###Transform the data: Now calculate absenteeism rate by dividing the absent hours by total standard hours for the year (52 weeks\\* 40 hours =2080)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMFGEmployees$AbsenceRate<-MFGEmployees$AbsentHours/2080*100\nstr(MFGEmployees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t8165 obs. of  14 variables:\n $ EmployeeNumber: int  1 2 3 4 5 6 7 8 9 10 ...\n $ Surname       : chr  \"Gutierrez\" \"Hardwick\" \"Delgado\" \"Simon\" ...\n $ GivenName     : chr  \"Molly\" \"Stephen\" \"Chester\" \"Irene\" ...\n $ Gender        : chr  \"F\" \"M\" \"M\" \"F\" ...\n $ City          : chr  \"Burnaby\" \"Courtenay\" \"Richmond\" \"Victoria\" ...\n $ JobTitle      : chr  \"Baker\" \"Baker\" \"Baker\" \"Baker\" ...\n $ DepartmentName: chr  \"Bakery\" \"Bakery\" \"Bakery\" \"Bakery\" ...\n $ StoreLocation : chr  \"Burnaby\" \"Nanaimo\" \"Richmond\" \"Victoria\" ...\n $ Division      : chr  \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n $ Age           : num  32 40.3 48.8 44.6 35.7 ...\n $ LengthService : num  6.02 5.53 4.39 3.08 3.62 ...\n $ AbsentHours   : num  36.6 30.2 83.8 70 0 ...\n $ BusinessUnit  : chr  \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n $ AbsenceRate   : num  1.76 1.45 4.03 3.37 0 ...\n```\n:::\n:::\n\n\n\n\n\nWe can now see our metric AbsenceRate has been calculated and created.\n\n###Explore The Data Part of collecting and managing data is 'Exploratory' Analysis.\n\nLets start with bar graphs of some of the categorical data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounts <- table(MFGEmployees$BusinessUnit)\nbarplot(counts, main = \"EmployeeCount By Business Units\", horiz = TRUE)\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-6-1.png)\n:::\n\n```{.r .cell-code}\ncounts <- table(MFGEmployees$Gender)\nbarplot(counts, main = \"EmployeeCount By Gender\", horiz = TRUE)\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-6-2.png)\n:::\n\n```{.r .cell-code}\ncounts <- table(MFGEmployees$Division)\nbarplot(counts, main = \"EmployeeCount By Division\", horiz = TRUE)\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-6-3.png)\n:::\n:::\n\n\n\n\n\nLets ask some of our questions answered through this exploratory analysis.\n\n**First of all, what is our absenteeism rate?**\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(MFGEmployees$AbsenceRate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.907265\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot() + geom_boxplot(aes(y = AbsenceRate, x =1), data = MFGEmployees) + coord_flip()\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-7-1.png)\n:::\n:::\n\n\n\n\n\nThe absence rate is 2.9.\n\n**Does anyone have excessive absenteeism?**\n\nThe boxplot shows the mean and standard deviation of the data. Any observations beyond 3 standard deviations shows up as dots. So at least under that definition of outliers, some people show way more absenteeism than 99% of employees\n\n**Does it vary across the organization?**\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n#library(RcmdrMisc)\nggplot() + geom_boxplot(aes(y = AbsenceRate, x = Gender), data = MFGEmployees) + coord_flip()\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-8-1.png)\n:::\n\n```{.r .cell-code}\nAnovaModel.1 <-aov(AbsenceRate ~ Gender, data=MFGEmployees)\nsummary(AnovaModel.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Df Sum Sq Mean Sq F value Pr(>F)    \nGender         1    496   495.6   97.77 <2e-16 ***\nResiduals   8163  41379     5.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\naggregate(MFGEmployees$AbsenceRate, list(MFGEmployees$Gender), FUN=mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Group.1        x\n1       F 3.157624\n2       M 2.664813\n```\n:::\n:::\n\n\n\n\n\nIt varies significantly by Gender.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + geom_boxplot(aes(y = AbsenceRate, x = Division), data = MFGEmployees) + coord_flip()\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-9-1.png)\n:::\n\n```{.r .cell-code}\nAnovaModel.2 <-aov(AbsenceRate ~ Division, data=MFGEmployees)\nsummary(AnovaModel.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Df Sum Sq Mean Sq F value  Pr(>F)   \nDivision       5     91  18.240   3.562 0.00322 **\nResiduals   8159  41783   5.121                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\naggregate(MFGEmployees$AbsenceRate, list(MFGEmployees$Division), FUN=mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Group.1        x\n1            Executive 2.323580\n2 FinanceAndAccounting 1.921890\n3       HumanResources 2.651743\n4             InfoTech 1.925995\n5                Legal 2.471724\n6               Stores 2.920856\n```\n:::\n:::\n\n\n\n\n\nIt varies significantly by Division.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnovaModel.3 <-aov(AbsenceRate ~Division*Gender, data=MFGEmployees)\nsummary(AnovaModel.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Df Sum Sq Mean Sq F value  Pr(>F)    \nDivision           5     91    18.2   3.602 0.00295 ** \nGender             1    496   495.9  97.942 < 2e-16 ***\nDivision:Gender    5      5     0.9   0.178 0.97078    \nResiduals       8153  41283     5.1                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\naggregate(MFGEmployees$AbsenceRate, list(MFGEmployees$Division,MFGEmployees$Gender), FUN=mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Group.1 Group.2        x\n1             Executive       F 2.976419\n2  FinanceAndAccounting       F 2.172804\n3        HumanResources       F 3.014491\n4              InfoTech       F 3.298112\n5                 Legal       F 3.298112\n6                Stores       F 3.169049\n7             Executive       M 1.779546\n8  FinanceAndAccounting       M 1.634077\n9        HumanResources       M 2.214311\n10             InfoTech       M 1.773538\n11                Legal       M 2.058530\n12               Stores       M 2.680788\n```\n:::\n:::\n\n\n\n\n\nIf varies significantly by the interaction of gender and division.\n\nThese are just a handful of the categorical summaries we could do.\n\n**Does AbsenceRate vary by length of service and age?**\n\nScatterplots and correlations help answer this.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot() + geom_point(aes(x = Age,y = AbsenceRate),data=MFGEmployees) + \n  geom_smooth(aes(x = Age,y = AbsenceRate),data=MFGEmployees,method = 'lm')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-11-1.png)\n:::\n\n```{.r .cell-code}\ncor(MFGEmployees$Age, MFGEmployees$AbsenceRate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8246129\n```\n:::\n:::\n\n\n\n\n\nThere is a strong correlation of Age and Absence Rate\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot() + geom_point(aes(x = LengthService,y = AbsenceRate),data=MFGEmployees) +\n  geom_smooth(aes(x = LengthService,y = AbsenceRate),data=MFGEmployees,method = 'lm')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-12-1.png)\n:::\n\n```{.r .cell-code}\ncor(MFGEmployees$LengthService, MFGEmployees$AbsenceRate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.04669242\n```\n:::\n:::\n\n\n\n\n\nThere is not a strong correlation between length of service and Absence Rate.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + geom_point(aes(x = LengthService,y = Age),data=MFGEmployees) + \n  geom_smooth(aes(x = LengthService,y = Age),data=MFGEmployees,method = 'lm')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-13-1.png)\n:::\n\n```{.r .cell-code}\ncor(MFGEmployees$Age, MFGEmployees$LengthService)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05623405\n```\n:::\n:::\n\n\n\n\n\nThere is not much correlation between age and length of service either.\n\nThis is as far as we will go in this article. We will defer the rest of the analyses to the part 2 blog article. In Part 1 of this blog article\n\nwe:\n\n-   Indicated that People Analytics is something that organizations can do themselves\n-   Indicated that it can be done in the R programming language as at least one possible tool\n-   Provided some basic terminology for People Analytics and Data Science.\n-   Provided a sample suggested framework for Data Science.\n-   Covered the first 2 steps of that framework for a People Analytics example- defining the problem and collecting and managing data.\n\nLet us know move on to step 3.\n\nReload the data and adjust it for corrections again\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMFGEmployees <- read.csv(\"MFGEmployees4.csv\")\n#write.csv(MFGEmployees,\"~/R Files/MFGEmployees4.csv\")\nMFGEmployees$AbsenceRate<-MFGEmployees$AbsentHours/2080*100\nsummary(MFGEmployees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n EmployeeNumber   Surname           GivenName            Gender         \n Min.   :   1   Length:8336        Length:8336        Length:8336       \n 1st Qu.:2085   Class :character   Class :character   Class :character  \n Median :4168   Mode  :character   Mode  :character   Mode  :character  \n Mean   :4168                                                           \n 3rd Qu.:6252                                                           \n Max.   :8336                                                           \n     City             JobTitle         DepartmentName     StoreLocation     \n Length:8336        Length:8336        Length:8336        Length:8336       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Division              Age         LengthService      AbsentHours    \n Length:8336        Min.   : 3.505   Min.   : 0.0121   Min.   :  0.00  \n Class :character   1st Qu.:35.299   1st Qu.: 3.5759   1st Qu.: 19.13  \n Mode  :character   Median :42.115   Median : 4.6002   Median : 56.01  \n                    Mean   :42.007   Mean   : 4.7829   Mean   : 61.28  \n                    3rd Qu.:48.667   3rd Qu.: 5.6239   3rd Qu.: 94.28  \n                    Max.   :77.938   Max.   :43.7352   Max.   :272.53  \n BusinessUnit        AbsenceRate     \n Length:8336        Min.   : 0.0000  \n Class :character   1st Qu.: 0.9196  \n Mode  :character   Median : 2.6926  \n                    Mean   : 2.9463  \n                    3rd Qu.: 4.5329  \n                    Max.   :13.1024  \n```\n:::\n\n```{.r .cell-code}\nMFGEmployees<-subset(MFGEmployees,MFGEmployees$Age>=18)\nMFGEmployees<-subset(MFGEmployees,MFGEmployees$Age<=65)\n```\n:::\n\n\n\n\n\n##3. Build The model One of the questions asked in the defining the goal step was 'whether it was possible to **predict** absenteeism?'\n\nAbsence Rate is a numeric continuous value. In the 'Building a model' step we have to chose what models/statistical algorithms to use. Prediction of a numerics continous values suggests a couple of models that could be brought to bear: Regression trees and linear regression. There are many more but for purposes of this article we will look at these\n\n###3.1 Regression Trees Regression Trees will allow for use of both categorical and numeric values as predictors.Lets choose the following data as potential predictors in this analysis:\n\n-   Gender\n-   Department Name\n-   Store Location\n-   Division\n-   Age\n-   Length of Service\n-   Business Unit\n\n**Absence Rate** will be the the 'target' or thing to be predicted.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rattle)   \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: tibble\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: bitops\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRattle: A free graphical interface for data science with R.\nVersion 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.\nType 'rattle()' to shake, rattle, and roll your data.\n```\n:::\n\n```{.r .cell-code}\nlibrary(magrittr) \nbuilding <- TRUE\nscoring  <- ! building\ncrv$seed <- 42 \nMYdataset <- MFGEmployees\nstr(MYdataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t8165 obs. of  14 variables:\n $ EmployeeNumber: int  1 2 3 4 5 6 7 8 9 10 ...\n $ Surname       : chr  \"Gutierrez\" \"Hardwick\" \"Delgado\" \"Simon\" ...\n $ GivenName     : chr  \"Molly\" \"Stephen\" \"Chester\" \"Irene\" ...\n $ Gender        : chr  \"F\" \"M\" \"M\" \"F\" ...\n $ City          : chr  \"Burnaby\" \"Courtenay\" \"Richmond\" \"Victoria\" ...\n $ JobTitle      : chr  \"Baker\" \"Baker\" \"Baker\" \"Baker\" ...\n $ DepartmentName: chr  \"Bakery\" \"Bakery\" \"Bakery\" \"Bakery\" ...\n $ StoreLocation : chr  \"Burnaby\" \"Nanaimo\" \"Richmond\" \"Victoria\" ...\n $ Division      : chr  \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n $ Age           : num  32 40.3 48.8 44.6 35.7 ...\n $ LengthService : num  6.02 5.53 4.39 3.08 3.62 ...\n $ AbsentHours   : num  36.6 30.2 83.8 70 0 ...\n $ BusinessUnit  : chr  \"Stores\" \"Stores\" \"Stores\" \"Stores\" ...\n $ AbsenceRate   : num  1.76 1.45 4.03 3.37 0 ...\n```\n:::\n\n```{.r .cell-code}\nMYinput <- c(\"Gender\", \"DepartmentName\", \"StoreLocation\", \"Division\",\n     \"Age\", \"LengthService\", \"BusinessUnit\")\nMYnumeric <- c(\"Age\", \"LengthService\")\nMYcategoric <- c(\"Gender\", \"DepartmentName\", \"StoreLocation\", \"Division\",\n     \"BusinessUnit\")\nMYtarget  <- \"AbsenceRate\"\nMYrisk    <- NULL\nMYident   <- \"EmployeeNumber\"\nMYignore  <- c(\"Surname\", \"GivenName\", \"City\", \"JobTitle\", \"AbsentHours\")\nMYweights <- NULL\nlibrary(rpart, quietly=TRUE)\nset.seed(crv$seed)\nMYrpart <- rpart(AbsenceRate ~ .,\n    data=MYdataset[, c(MYinput, MYtarget)],\n    method=\"anova\",\n    parms=list(split=\"information\"),\n      control=rpart.control(minsplit=10,\n           maxdepth=10,\n        usesurrogate=0, \n        maxsurrogate=0))\nfancyRpartPlot(MYrpart, main=\"Decision Tree MFGEmployees $ AbsenceRate\")\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-15-1.png)\n:::\n:::\n\n\n\n\n\nThe regression decision tree shows that age is a big factor in determining absence rate with gender playing a small part in one of the age ranges: \\>43 and \\<52 with males having a lower absence rate in this group. Almost all categorical information other than gender doesnt look like its helps in prediction.\n\nNow lets look at linear regression as another model. The restriction in linear regression is that it can only accept non-categorical variables. Categorical variables can sometimes be made numeric through transformation, but that is beyond the scope of this article.\n\n###3.2 Linear Regression\n\nIn linear regression, then, we will need to restrict it to numeric variables:\n\n-   Age\n-   Length of Service\n\nbeing used to predict absence rate.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Linear Regression Model\nRegressionCurrentData <- lm(AbsenceRate~Age+LengthService, data=MFGEmployees)\nsummary(RegressionCurrentData)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = AbsenceRate ~ Age + LengthService, data = MFGEmployees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.3578 -0.8468 -0.0230  0.8523  5.1030 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -5.190213   0.068959  -75.27   <2e-16 ***\nAge            0.202593   0.001510  134.16   <2e-16 ***\nLengthService -0.085309   0.005652  -15.09   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.264 on 8162 degrees of freedom\nMultiple R-squared:  0.6887,\tAdjusted R-squared:  0.6886 \nF-statistic:  9027 on 2 and 8162 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n\n\nThe summary shows an adjusted R-squared of .68 which means approximately 68% of the variance is accounted by age and length of service. The variables are both significant at Pr(\\>\\|t\\|) of \\<2e-16. These results are using the entirety of the existing data to predict itself.\n\nGraphically it look like this:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#2D plot of Age and AbsenceRate\nlibrary(ggplot2)\n\nggplot() + geom_point(aes(x = Age,y = AbsenceRate),data=MFGEmployees) +geom_smooth(aes(x = Age,y = AbsenceRate),data=MFGEmployees,method = 'lm')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-17-1.png)\n:::\n\n```{.r .cell-code}\n#3D Scatterplot  of Age and Length of Service with Absence Rate - with Coloring and Vertical Lines\n# and Regression Plane \nlibrary(scatterplot3d) \n\ns3d <-scatterplot3d(MFGEmployees$Age,MFGEmployees$LengthService,MFGEmployees$AbsenceRate, pch=16, highlight.3d=TRUE,\n                    type=\"h\", main=\"Absence Rate By Age And Length of Service\")\nfit <- lm(MFGEmployees$AbsenceRate ~ MFGEmployees$Age+MFGEmployees$LengthService) \ns3d$plane3d(fit)\n```\n\n::: {.cell-output-display}\n![](PAExampleUsingR_files/figure-epub/unnamed-chunk-17-2.png)\n:::\n:::\n\n\n\n\n\n## 4.Evaluate And Critique Model\n\nUp till now we have concentrated on producing a couple of models. The effort so far has had one weakness. **We have used all of our data for 2015 to generate the models.** They can both predict, but the prediction are based on existing data- dat already known. We dont know how well it will predict on data it hasnt seen yet.\n\nTo evaluate and critique the models, we need to train the model using part of the data and hold out a portion to test on.We will divide the data into 10 parts- using 9 parts as training data and 1 part as testing data, and alternate which are the 9 and the 1, so that each of the 10 parts gets to be training data 9 times and testing data once.\n\nThe R \"caret\" library helps us do that. We will run both a regression tree and linear regression and compare how they do against each other.\n\nFirst the Linear Regression\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MFGEmployees <- readRDS(file=\"c:/Users/Lyndon.A3HR/Documents/MFGEmployees.Rda\")\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n```{.r .cell-code}\nset.seed(998)\ninTraining <- createDataPartition(MFGEmployees$BusinessUnit, p = .75, list = FALSE)\ntraining <- MFGEmployees[inTraining,]\ntesting <- MFGEmployees[ - inTraining,]\n\nfitControl <- trainControl(## 10-fold CV\nmethod = \"repeatedcv\",\n                           number = 10,\n                           ## repeated ten times\nrepeats = 10)\n\nset.seed(825)\nlmFit1 <- train(AbsenceRate ~ Age + LengthService, data = training,\n                 method = \"lm\",\n                 trControl = fitControl)\nlmFit1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear Regression \n\n6124 samples\n   2 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 10 times) \nSummary of sample sizes: 5511, 5511, 5512, 5512, 5511, 5512, ... \nResampling results:\n\n  RMSE      Rsquared   MAE     \n  1.269977  0.6909094  1.007153\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n```\n:::\n:::\n\n\n\n\n\nThe rSquared shows a value of .688 which means even with sampling different parts of the data on 10 fold cross validation the use of age and length of service seems to be pretty robust so far.\n\nNext the decision tree. The first time with just the numeric variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(825)\nrpartFit1 <- train(AbsenceRate ~ Age + LengthService, data = training,\n                 method = \"rpart\",\n                 trControl = fitControl,\n                 maxdepth = 5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n```\n:::\n\n```{.r .cell-code}\nrpartFit1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n6124 samples\n   2 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 10 times) \nSummary of sample sizes: 5511, 5511, 5512, 5512, 5511, 5512, ... \nResampling results across tuning parameters:\n\n  cp          RMSE      Rsquared   MAE     \n  0.06330829  1.431901  0.6062148  1.140352\n  0.09451716  1.557060  0.5344593  1.260302\n  0.48920642  1.963226  0.4741241  1.607013\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.06330829.\n```\n:::\n:::\n\n\n\n\n\nYou will notice that the decision tree with 10 fold cross validation didnt perform as well with an RSquared of approximately .60\n\nThe second time with the original categorical and numeric varibles used.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(825)\nrpartFit2 <- train(AbsenceRate ~ Gender + DepartmentName + StoreLocation + Division + Age + LengthService + BusinessUnit, data = training,\n                 method = \"rpart\",\n                 trControl = fitControl,\n                 maxdepth = 5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n```\n:::\n\n```{.r .cell-code}\nrpartFit2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCART \n\n6124 samples\n   7 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 10 times) \nSummary of sample sizes: 5511, 5511, 5512, 5512, 5511, 5512, ... \nResampling results across tuning parameters:\n\n  cp          RMSE      Rsquared   MAE     \n  0.06330829  1.431901  0.6062148  1.140352\n  0.09451716  1.557060  0.5344593  1.260302\n  0.48920642  1.963226  0.4741241  1.607013\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.06330829.\n```\n:::\n:::\n\n\n\n\n\nHere when you include all originally used vaiables in 10 fold cross validation, the RSquared changed little and is still around .60.\n\nSo far the linear regression is performing better\n\n##5.Present Results and Document\n\nThe presenting of results and documenting is something that R helps in. You may not have realized it, but the R Markdown language has been used to create the full layout of these two blog articles. HTML,PDF and Word formats can be produced.\n\nR Markdown allows the reader to see exactly what you having been doing , so that an independent person can replicate your results, to confirm what you have done. It shows the R code/commands, the statistical results and graphics.\n\nThese are:\n\n-   Absenteeism-Part1.Rmd and\n-   Absenteeism-Part2.Rmd\n\nFor presentation formats beyond this, you may have to use other tools.\n\n##6.Deploy Model Once you have evaluated your model(s) and chosen to use them, they need to be deployed so that they can be used. At the simplest level, 'deploy' can mean using the 'predict' function in R (where applicable) in conjunction with your model.\n\nIn R, you can also 'publish' you model as an R HTTP service so that others can use it.(That is beyond the scope of this article)\n\n**Can it predict next year absenteeism?**\n\nLets predict the 2016 Absenteeism from the 2015 model.\n\nIf we make the simplifying assumption that nobody quits and nobody new comes in, we can take the 2015 data and add 1 to age and 1 to years of service for an approximation of new 2016 data before we get to 2016.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Apply model\n#Generate 2016 data\nAbsence2016Data<-MFGEmployees\nAbsence2016Data$Age<-Absence2016Data$Age+1\nAbsence2016Data$LengthService<-Absence2016Data$LengthService+1\nAbsence2016Data$AbsenceRate<-0\nAbsence2016Data$AbsenceRate<-predict(lmFit1,Absence2016Data)\n```\n:::\n\n\n\n\n\nTo get single estimate for 2016 we ask for mean of absence rate.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(Absence2016Data$AbsenceRate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.040885\n```\n:::\n\n```{.r .cell-code}\nmean(MFGEmployees$AbsenceRate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.907265\n```\n:::\n:::\n\n\n\n\n\nThe first figure above is the 2016 prediction, the second is the 2015 actual for comparison.\n\n**If so, how well can it predict?**\n\nAs mentioned previously, about 68% of the variation is accounted for in a linear regression model using age and length of service.\n\n**Can we reduce our absenteeism?**\n\nOn the surface, only getting the age reduced and length of service increased will reduce absensteeism with this model.\n\nObviously, absenteeism is much more complex that just the rudimentary data we have collected. A serious look at this metric and problem would require more and different kinds of data. As mentioned before , the raw data used in this article and analysis is totally contrived to illustrate an example.\n\n#Final Comments\n\nThe purposes of these two blogs articles was to:\n\n-   show that R could be used to do People Analytics\n-   show that People Analytics is the application of the Data Science to People (HR) Management and decision making.\n-   show by a rudimentary/simple (not necessarily rigorous) example that the 'data science' capability is in your hands.\n-   show that 'free' tools can be used to start the 'People Analytics' journey.\n\nIts time to apply data science to People Management, and be data-driven.\n\nEnjoy the journey!\n",
    "supporting": [
      "PAExampleUsingR_files/figure-epub"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}